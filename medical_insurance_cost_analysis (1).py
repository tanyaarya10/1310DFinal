# -*- coding: utf-8 -*-
"""Medical Insurance Cost Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ol6bYnwKm-No-Vvmw7JGzkJiUcs53ojP

## I310D Final Project: Medical Insurance Cost Analysis


---


Mia Saavedra, Tanya Arya,  Amolika Kondapalli, Jisoo Park

School of Information, The University of Texas at Austin

I 310D: Introduction to Human-Centered Data Science

Professor Abhijit Mishra

May 6 2024


---

**Dataset**

https://www.kaggle.com/datasets/rahulvyasm/medical-insurance-cost-prediction

This dataset includes 2.7K rows and 7 columns that describe patients in terms of demographics, habits and medical insurance cost.

**Goal**

Analyze the factors that influence medical expenses including age, BMI, sex, smoking status, region, and number of children.

*Which factor has the greatest positive correlation with medical charges?*

## 0. Install and Import Libraries
"""

import pandas as pd
import numpy as np
import scipy
!pip install researchpy
from matplotlib import pyplot as plt

"""##1. Convert Data to DataFrame
- Transformation to df
"""

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

medical_insurance_df = pd.read_csv("medical_insurance.csv")

medical_insurance_df.head()

"""##2. Clean Data
- Delete duplicate rows
- Delete null attributes
"""

# Report number of duplicates before removing
number_of_duplicates = medical_insurance_df.duplicated().sum()
print (f" Number of duplicates before : {number_of_duplicates}")

# Delete duplicate rows
final_data = medical_insurance_df.drop_duplicates()

# Report number of duplicates after removing
number_of_duplicates = final_data.duplicated().sum()
print (f" Number of duplicates after removing : {number_of_duplicates}")

# Remove rows with null attributes
final_data = final_data.dropna()

# Print the DataFrame after removing rows with null attributes
final_data

# Concise summary of Final DataFrame
final_data.info()

"""## 3. Descriptive Statistics & Vistualizations
- Uses df.describe() method
- Age, BMI, Charges displays histograms (distribution of continuous numerical data)
- Age, Sex, Smoker, Region, Number of Children displays pie charts (proportion of categorical data)

Age
"""

# Calculates descriptive statistics for the "age" column of the DataFrame
print('Descriptive Statistics for Age')
final_data["age"].describe()

# Plot histogram
plt.hist(final_data["age"], bins=12, range=(10, 65), edgecolor='black')
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

# Pie Chart

# Define age categories
age_bins = [0, 20, 30, 40, 50, 60, 70, float('inf')]

# Adjusting labels to match the number of bins
age_labels = ['0-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+']

# Cut the 'age' column into bins
final_data['age_group'] = pd.cut(final_data['age'], bins=age_bins, labels=age_labels, right=False)

# Count the number of each category in 'age_group' column
age_counts = final_data['age_group'].value_counts()

# Create a pie chart
plt.figure(figsize=(8, 6))
plt.pie(age_counts, labels=age_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Age Groups')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

"""BMI (Body Mass Index)"""

# Calculates descriptive statistics for the "BMI" column of the DataFrame
print('Descriptive Statistics for BMI')
final_data["bmi"].describe()

# Plot histogram
plt.hist(final_data["bmi"], bins=10, edgecolor='black')
plt.title('Histogram of BMI')
plt.xlabel('BMI')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

"""Medical Charges"""

# Calculates descriptive statistics for the "Charges" column of the DataFrame
print('Descriptive Statistics for Insurance Charge')
final_data["charges"].describe()

# Plot histogram
plt.hist(final_data["charges"], bins=10, edgecolor='black')
plt.title('Histogram of Charges')
plt.xlabel('Charges ($)')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()

"""Sex

"""

# Calculates descriptive statistics for the "Sex" column of the DataFrame
print('Descriptive Statistics for Insurance Charge')
final_data["sex"].describe()

# Count the number of males and females
sex_counts = final_data['sex'].value_counts()

# Create a pie chart
plt.figure(figsize=(6, 6))
plt.pie(sex_counts, labels=sex_counts.index, autopct='%1.1f%%', startangle=140, colors=['lightblue', 'lightpink'])
plt.title('Sex Distribution')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# Calculate & print percentages of males and females in the sample data
print('Percentages of Male and Female in Sample')
(final_data.groupby('sex').size()/final_data['sex'].count())*100

"""Smoker"""

# Descriptive statistics for the smoker column
smoker_descriptive = final_data['smoker'].describe()
print (final_data['smoker'].describe())

# Prepare data for pie chart
smoker_counts = final_data['smoker'].value_counts()

# Plotting pie chart for smoker/nonsmoker
plt.subplot(1, 2, 2)
plt.pie(smoker_counts, labels=smoker_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Smoker vs Nonsmoker')

plt.tight_layout()
plt.show()

"""Region"""

# Descriptive statistics for the smoker column
smoker_descriptive = final_data['region'].describe()
print (final_data['region'].describe())

# Prepare data for pie chart
region_counts = final_data['region'].value_counts()

# Plotting pie chart for region
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.pie(region_counts, labels=region_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Region Distribution')

"""Number of Children"""

# Descriptive statistics for the number of children column
children_descriptive = final_data['children'].describe()
print(children_descriptive)

# Prepare data for pie chart
children_counts = final_data['children'].value_counts()

# Plotting pie chart for number of children
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.pie(children_counts, labels=children_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Number of Children Distribution')

# Show descriptive statistics
plt.subplot(1, 2, 2)
plt.text(0.1, 0.9, children_descriptive.to_string(), fontsize=10, ha='left')  # Convert Series to string using to_string()
plt.axis('off')  # Hide axes
plt.show()

"""##4. Statistical Tests

**Correlations**
- Pearson correlation coefficient (r) measuring linear correlation

Age

Steps include finding r and R-squared value.
"""

from scipy.stats import pearsonr

p = pearsonr(final_data["age"],final_data["charges"])
print ("r:", p[0])

r_squared = p[0] ** 2
print("R-squared:", r_squared)

"""BMI (Body Mass Index)

Steps include finding and printing r and the R-squared value.
"""

from scipy.stats import pearsonr

p = pearsonr(final_data["bmi"],final_data["charges"])
print ("r:", p[0])

r_squared = p[0] ** 2
print("R-squared:", r_squared)

"""Correlation Matrix

Steps include selecting only numerical columns for correlation calculation,computing the correlation matrix, and plotting the heat map.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Selecting only numerical columns for correlation calculation
numerical_df = final_data.select_dtypes(include=['number'])

# Compute correlation matrix
correlation_matrix = numerical_df.corr()
print (correlation_matrix)

# Calculate correlation matrix
corr_matrix = final_data[['age', 'bmi', 'charges']].corr()

# Plot heatmap
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix: Age, BMI, and Charges')
plt.show()

"""**T-Tests**
- Determine if there is a significant difference between the means of two groups
- T-statistic measures the size of the difference relative to the variation in the sample data
- P-Value validate a hypothesis against observed data (hypothesis)
We considered a p-value below 0.05 to be statistically significant.

Sex
- Male/Female

Steps include seperating male and female, performing the t-test and printing the p-value and interpretations.
"""

from scipy.stats import ttest_ind

# Separate male and female data
male_data = final_data[final_data['sex'] == 'male']['charges']
female_data = final_data[final_data['sex'] == 'female']['charges']

# Performing the t-test
t_statistic, p_value = ttest_ind(male_data, female_data, nan_policy='omit')

# Printing the T-statistic and P-value
print("T-Statistic:", t_statistic)
print("P-Value:", p_value)

# Interpretation
alpha = 0.05
if not np.isnan(t_statistic) and not np.isnan(p_value):
    if p_value < alpha:
        print("Reject the null hypothesis. There is a significant difference between the two groups.")
    else:
        print("Fail to reject the null hypothesis. There is no significant difference between the two groups.")
else:
    print("Unable to perform t-test due to missing data.")

"""Smoker
- Smoker/Non-smoker

Steps include data
"""

import pandas as pd
from scipy.stats import ttest_ind

# Create DataFrame
df = pd.DataFrame(final_data)

# Separate smoker and nonsmoker data
smoker_data = df[df['smoker'] == 'yes']['charges']
nonsmoker_data = df[df['smoker'] == 'no']['charges']

# Performing the t-test
t_statistic, p_value = ttest_ind(smoker_data, nonsmoker_data, nan_policy='omit')

# Printing the results
print("T-Statistic:", t_statistic)
print("P-Value:", p_value)

if p_value < 0.05:
    print("Reject the null hypothesis. There is a significant difference between the two groups.")
else:
    print("Fail to reject the null hypothesis. There is no significant difference between the two groups.")

"""**ANOVA Test**
- Determine if there is a significant difference between the means of any two groups and how they are related.
- F-statistic measures the size of the difference relative to the variation in the sample data
- P-Value validate a hypothesis against observed data (hypothesis)
We considered a p-value below 0.05 to be statistically significant.

Region

Steps for ANOVA:

Create a list of charges for each region

Perform ANOVA test

Print ANOVA table

Create a list of charges for each number of children

Print results, interpretation, and table
"""

import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import f_oneway  # Add this import statement

# Create a list of charges for each region
df = final_data
region_groups = [df[df['region'] == 'southwest']['charges'],
                 df[df['region'] == 'southeast']['charges'],
                 df[df['region'] == 'northwest']['charges'],
                 df[df['region'] == 'northeast']['charges']]

# Perform ANOVA test
f_statistic, p_value = f_oneway(*region_groups)

# Print the results
print("F-Statistic:", f_statistic)
print("P-Value:", p_value)

# Interpretation
alpha = 0.05
if p_value < alpha:
    print("Reject the null hypothesis. There is a significant difference in charges among different regions.")
else:
    print("Fail to reject the null hypothesis. There is no significant difference in charges among different regions.")

# Perform ANOVA
model = ols('charges ~ C(region)', data=df).fit()
anova_table = sm.stats.anova_lm(model, typ=2)

# Print ANOVA table
print(anova_table)

"""Number of Children

Steps for ANOVA:

Perform ANOVA

Print ANOVA table

Create a list of charges for each number of children

Perform ANOVA test

Print results and interpretation
"""

# Perform ANOVA
model = ols('charges ~ C(children)', data=df).fit()
anova_table = sm.stats.anova_lm(model, typ=2)

# Print ANOVA table
print(anova_table)

# Create a list of charges for each number of children
children_groups = []
for num_children in df['children'].unique():
    children_groups.append(df[df['children'] == num_children]['charges'])

# Perform ANOVA test
f_statistic, p_value = f_oneway(*children_groups)

# Print the results
print("F-Statistic:", f_statistic)
print("P-Value:", p_value)

# Interpretation
alpha = 0.05
if p_value < alpha:
    print("Reject the null hypothesis. There is a significant difference in charges based on the number of children.")
else:
    print("Fail to reject the null hypothesis. There is no significant difference in charges based on the number of children.")

"""Linear Regression
- For non-catagorical factors (Age & BMI)
- The coefficeints and intercepts are used for the equation of the line of best fit.
- The mean squared error tells us the average squared difference between the predicted and actual values.

**Age**

Steps for linear regression:

Split the data into training and testing sets

Create and fit the linear regression model

Make predictions on the test set

Print model coefficients

Evaluate the model

Plot the regression line
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Prepare the data for linear regression
X = final_data[['age']]
y = final_data['charges']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Print model coefficients
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

# Plot the regression line
plt.scatter(X_test, y_test, color='blue')
plt.plot(X_test, y_pred, color='red')
plt.xlabel('Age')
plt.ylabel('Charges ($)')
plt.title('Linear Regression: Age vs Charges')
plt.show()

"""BMI

Steps for linear regression:

Split the data into training and testing sets

Create and fit the linear regression model

Make predictions on the test set

Print model coefficients

Evaluate the model

Plot the regression line
"""

# Prepare the data for linear regression
X = final_data[['bmi']]
y = final_data['charges']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Print model coefficients
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error:", mse)
print("R^2 Score:", r2)

# Plot the regression line
plt.scatter(X_test, y_test, color='blue')
plt.plot(X_test, y_pred, color='red')
plt.xlabel('BMI')
plt.ylabel('Charges ($)')
plt.title('Linear Regression: BMI vs Charges')
plt.show()

"""##5. Data Visualization

Box Plots
- Show distributions of numeric data values, especially between multiple groups. Through this method, we can identify outliers and the quartiles.
"""

# Plotting box plots

# Age
plt.figure(figsize=(12, 6))
sns.boxplot(x='age', y='charges', data=df)
plt.title('Age vs Charges')
plt.xlabel('Age')
plt.ylabel('Charges ($)')
plt.show()

# BMI
desired_ticks = np.arange(15, 46, 5)
plt.figure(figsize=(12, 6))
sns.boxplot(x='bmi', y='charges', data=df)
plt.title('BMI vs Charges')
plt.xlabel('BMI')
plt.ylabel('Charges ($)')
plt.xlim(20, 40)  # Set limits for BMI axis
plt.show()

# Sex
plt.figure(figsize=(12, 6))
sns.boxplot(x='sex', y='charges', data=df)
plt.title('Sex vs Charges')
plt.xlabel('Sex')
plt.ylabel('Charges ($)')
plt.show()

# Smoker
plt.figure(figsize=(12, 6))
sns.boxplot(x='smoker', y='charges', data=df)
plt.title('Smoker vs Charges')
plt.xlabel('Smoker')
plt.ylabel('Charges($)')
plt.show()

# Region
plt.figure(figsize=(12, 6))
sns.boxplot(x='region', y='charges', data=df)
plt.title('Region vs Charges')
plt.xlabel('Region')
plt.ylabel('Charges ($)')
plt.show()

# Children
plt.figure(figsize=(12, 6))
sns.boxplot(x='children', y='charges', data=df)
plt.title('Children vs Charges')
plt.xlabel('Children')
plt.ylabel('Charges($)')
plt.show()

"""# Data License: Released under MIT License

Copyright (c) 2013 Mark Otto.

Copyright (c) 2017 Andrew Fong.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

# Sources

M Rahul Vyas. (2024). Medical Insurance Cost Prediction. Kaggle.com. https://www.kaggle.com/datasets/rahulvyasm/medical-insurance-cost-prediction



GeeksforGeeks. (2018, June 10). EDA Exploratory Data Analysis in Python. GeeksforGeeks; GeeksforGeeks. https://www.geeksforgeeks.org/exploratory-data-analysis-in-python/

T-test with Python. (2015). Pythonfordatascience.org. https://www.pythonfordatascience.org/independent-samples-t-test-python/


Matplotlib Pie Charts. (2024). W3schools.com. https://www.w3schools.com/python/matplotlib_pie_charts.asp


Comparing several means (one-way ANOVA) â€” Learning Statistics with Python. (2022). Github.io. https://ethanweed.github.io/pythonbook/05.03-anova.html


Renesh Bedre. (2018, October 22). How to Perform ANOVA in Python. RS Blog. https://www.reneshbedre.com/blog/anova.html
"""